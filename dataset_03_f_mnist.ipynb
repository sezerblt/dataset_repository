{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP5Kc8swq+W3+YGdy1nDU2/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sezerblt/dataset_repository/blob/main/dataset_03_f_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9bQXhSGQ_fM"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot\n",
        "from keras.datasets import fashion_mnist\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "veriseti yükleme ve veri önişleme"
      ],
      "metadata": {
        "id": "q3skaCivZ-Ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getNormalizeDataset():\n",
        "  X_train,Y_train=fashion_mnist.load_data()[0]\n",
        "  X_train=X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\n",
        "  X_train=X_train.astype(\"float32\")\n",
        "  X_TRAIN=X_train/255.0\n",
        "  Y_TRAIN = to_categorical(Y_train)\n",
        "\n",
        "  (X_test,Y_test)=fashion_mnist.load_data()[1]\n",
        "  X_test=X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)\n",
        "  X_test=X_test.astype(\"float32\")\n",
        "  X_TEST=X_test/255.0\n",
        "  Y_TEST = to_categorical(Y_test)\n",
        "  return X_TRAIN,Y_TRAIN,X_TEST,Y_TEST\n"
      ],
      "metadata": {
        "id": "mtobXT7MS5HU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model oluşturma"
      ],
      "metadata": {
        "id": "UmVJ9gC0aGNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setModel(inp_sh):\n",
        "  conv2d_1=Conv2D(filters=32,\n",
        "                  kernel_size=(3,3),\n",
        "                  activation=\"relu\",\n",
        "                  padding=\"same\",\n",
        "                  kernel_initializer=\"he_uniform\",\n",
        "                  input_shape=(inp_sh[1],inp_sh[2],1)\n",
        "  )\n",
        "  max_pool=MaxPooling2D(pool_size=(2,2))\n",
        "  flat=Flatten()\n",
        "  dense_1=Dense(units=100,activation=\"relu\",\n",
        "                kernel_initializer=\"he_uniform\")\n",
        "  dense_2=Dense(units=10,activation=\"softmax\")\n",
        "  opt_comp=SGD(lr=0.01,momentum=0.9)\n",
        "\n",
        "  model=Sequential()\n",
        "  \n",
        "  model.add(conv2d_1)\n",
        "  model.add(max_pool)\n",
        "  model.add(flat)\n",
        "  model.add(dense_1)\n",
        "  model.add(dense_2)\n",
        "  model.compile(optimizer=opt_comp,\n",
        "                loss=\"categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"]\n",
        "  )\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "ZWO8RjHJZ4dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "modelin kullanarak performans ölçümü"
      ],
      "metadata": {
        "id": "jVmD14OuaO6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateModel(x_data,y_data,n_splits=5):\n",
        "  scores_list=list()\n",
        "  history_list=list()\n",
        "  kfold=KFold(n_splits=n_splits,shuffle=True,random_state=1)\n",
        "  for train_i,test_i in kfold.split(x_data):\n",
        "    model=setModel(x_data.shape)\n",
        "    x_train_i=x_data[train_i]\n",
        "    y_train_i=y_data[train_i]\n",
        "    x_test_i=x_data[test_i]\n",
        "    y_test_i=y_data[test_i]\n",
        "\n",
        "    history=model.fit(x_train_i,\n",
        "                           y_train_i,\n",
        "                           epochs=3,\n",
        "                           batch_size=32,\n",
        "                           validation_data=(x_test_i,y_test_i),\n",
        "                           verbose=0\n",
        "    )\n",
        "    _,acc=model.evaluate(x_test_i,y_test_i,verbose=0)\n",
        "    #print(f\"score:{scr*100}\")\n",
        "    print(f\"dogruluk orani: {(acc*100.0)}\")\n",
        "\n",
        "    scores_list.append(acc)\n",
        "    history_list.append(history)\n",
        "    return scores_list,history_list"
      ],
      "metadata": {
        "id": "QrzYJY_uZ3hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "veri setinin cross ve acc grafigini incele"
      ],
      "metadata": {
        "id": "NhA943GId-zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summaryHistory(histories):\n",
        "  for i in range(len(histories)):\n",
        "    pyplot.subplot(211)\n",
        "    pyplot.title(\"cross entropy loss\")\n",
        "    pyplot.plot(histories[i].history[\"loss\"],\n",
        "                color=\"blue\",label=\"train loss\")\n",
        "    pyplot.plot(histories[i].history[\"val_loss\"],\n",
        "                color=\"red\",label=\"test loss\")\n",
        "    \n",
        "    pyplot.subplot(212)\n",
        "    pyplot.title(\"Accuracy classification\")\n",
        "    pyplot.plot(histories[i].history[\"accuracy\"],\n",
        "                color=\"blue\",label=\"train accuracy\")\n",
        "    pyplot.plot(histories[i].history[\"val_accuracy\"],\n",
        "                color=\"red\",label=\"test accuracy\")\n",
        "  pyplot.show()"
      ],
      "metadata": {
        "id": "fr1Nq29MeCHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "score performans ölçümü"
      ],
      "metadata": {
        "id": "4_CxTernfon4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summaryScore(scores):\n",
        "  print(f\"dogruluk degerleri : ortalama{mean(scores)*100} ,std:{std(scores)*100} ,n:{len(scores)}\")\n",
        "  pyplot.boxplot(scores)\n",
        "  pyplot.show()"
      ],
      "metadata": {
        "id": "7j7Eo0VbfwFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "basla"
      ],
      "metadata": {
        "id": "oz5lzsvDgnc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run():\n",
        "  x_train,y_train,x_test,y_test=getNormalizeDataset()\n",
        "  scores , histories=evaluateModel(x_train,y_train,5)\n",
        "  summaryHistory(histories)\n",
        "  summaryScore(scores)\n"
      ],
      "metadata": {
        "id": "SkzvlXorgyZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def savedModel():\n",
        "  x_train,y_train,x_test,y_test=getNormalizeDataset()\n",
        "  model=setModel(x_train.shape)\n",
        "  model.fit(x_train,y_train,epochs=3,batch_size=32)\n",
        "  _, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print(\"> %.3f\" % (acc * 100.0))\n",
        "  model.save(\"final_model.h5\")\n",
        "savedModel()"
      ],
      "metadata": {
        "id": "GfmIeK93vCay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "3NiZsnm2wsH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####od olarak biçimlendirilmiştir\n",
        "\n"
      ],
      "metadata": {
        "id": "7q5p-1ZC0jZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "  # load dataset\n",
        "  (trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
        "  # reshape dataset to have a single channel\n",
        "  trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "  testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "  # one hot encode target values\n",
        "  trainY = to_categorical(trainY)\n",
        "  testY = to_categorical(testY)\n",
        "  return trainX, trainY, testX, testY\n",
        "\n",
        "def prep_pixels(train, test):\n",
        "  # convert from integers to floats\n",
        "  train_norm = train.astype(\"float32\")\n",
        "  test_norm = test.astype(\"float32\")\n",
        "  # normalize to range 0-1\n",
        "  train_norm = train_norm / 255.0\n",
        "  test_norm = test_norm / 255.0\n",
        "  # return normalized images\n",
        "  return train_norm, test_norm\n",
        "\n",
        "def define_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation=\"relu\", kernel_initializer=\"he_uniform\",\n",
        "  input_shape=(28, 28, 1)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(100, activation=\"relu\", kernel_initializer=\"he_uniform\"))\n",
        "  model.add(Dense(10, activation=\"softmax\"))\n",
        "  # compile model\n",
        "  opt = SGD(lr=0.01, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "  return model\n",
        "\n",
        "def evaluate_model(dataX, dataY, n_folds=5):\n",
        "  scores, histories = list(), list()\n",
        "  # prepare cross validation\n",
        "  kfold = KFold(n_folds, shuffle=True, random_state=1)\n",
        "  # enumerate splits\n",
        "  for train_ix, test_ix in kfold.split(dataX):\n",
        "    model = define_model()\n",
        "    # select rows for train and test\n",
        "    trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix],dataY[test_ix]\n",
        "    history = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX,testY), verbose=0)\n",
        "    # evaluate model\n",
        "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
        "  print(\"> %.3f\" % (acc * 100.0))\n",
        "  # append scores \n",
        "  scores.append(acc)\n",
        "  histories.append(history)\n",
        "  return scores, histories\n",
        "\n",
        "def summarize_diagnostics(histories):\n",
        "  for i in range(len(histories)):\n",
        "    # plot loss\n",
        "    pyplot.subplot(211)\n",
        "    pyplot.title(\"Cross Entropy Loss\")\n",
        "    pyplot.plot(histories[i].history[\"loss\"], color=\"blue\", label=\"train\")\n",
        "    pyplot.plot(histories[i].history[\"val_loss\"], color=\"orange\", label=\"test\")\n",
        "    # plot accuracy\n",
        "    pyplot.subplot(212)\n",
        "    pyplot.title(\"Classification Accuracy\")\n",
        "    pyplot.plot(histories[i].history[\"acc\"], color=\"blue\", label=\"train\")\n",
        "    pyplot.plot(histories[i].history[\"val_acc\"], color=\"orange\", label=\"test\")\n",
        "  pyplot.show()\n",
        "\n",
        "def summarize_performance(scores):\n",
        "  # print summary\n",
        "  print(\"Accuracy: mean=%.3f std=%.3f, n=%d\" % (mean(scores)*100, std(scores)*100,\n",
        "  len(scores)))\n",
        "  # box and whisker plots of results\n",
        "  pyplot.boxplot(scores)\n",
        "  pyplot.show()\n",
        "\n",
        "\n",
        "def run_test_harness():\n",
        "  trainX, trainY, testX, testY = load_dataset()\n",
        "  # prepare pixel data\n",
        "  trainX, testX = prep_pixels(trainX, testX)\n",
        "  # evaluate model\n",
        "  scores, histories = evaluate_model(trainX, trainY)\n",
        "  # learning curves\n",
        "  summarize_diagnostics(histories)\n",
        "  # summarize estimated performance\n",
        "  summarize_performance(scores)\n",
        "\n",
        "run_test_harness()"
      ],
      "metadata": {
        "id": "DZ_pmgZW0gcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import load_img\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from keras.models import load_model\n",
        "import numpy\n",
        "def load_image(filename):\n",
        "  # load the image\n",
        "  img = load_img(filename, grayscale=True, target_size=(28, 28))\n",
        "  # convert to array\n",
        "  img = img_to_array(img)\n",
        "  # reshape into a single sample with 1 channel\n",
        "  img = img.reshape(1, 28, 28, 1)\n",
        "  # prepare pixel data\n",
        "  img = img.astype(\"float32\")\n",
        "  img = img /255.0\n",
        "  return img\n",
        "\n",
        "def run_example():\n",
        "  # load the image\n",
        "  img = load_image(\"sample_image.png\")\n",
        "  # load model\n",
        "  model = load_model(\"final_model.h5\")\n",
        "  # predict the class\n",
        "  result = model.predict_classes(img)\n",
        "  print(result[0])\n",
        "\n",
        "run_example()"
      ],
      "metadata": {
        "id": "tsK4MipN4FNX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}